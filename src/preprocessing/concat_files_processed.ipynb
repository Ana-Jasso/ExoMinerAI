{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12bd3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Librer√≠as ---\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d587393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for K2Processed.csv:\n",
      "Status\n",
      "CP    1019\n",
      "FP      10\n",
      "PC     192\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\k'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\k'\n",
      "C:\\Users\\anala\\AppData\\Local\\Temp\\ipykernel_26392\\579437714.py:2: SyntaxWarning: invalid escape sequence '\\k'\n",
      "  k2_df = pd.read_csv('../../data/processed\\k2Processed.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read the K2Processed.csv file into a DataFrame\n",
    "k2_df = pd.read_csv('../../data/processed\\k2Processed.csv')\n",
    "\n",
    "# Normalize disposition labels\n",
    "k2_df['disposition'] = k2_df['disposition'].replace({\n",
    "    'CONFIRMED': 'CP',\n",
    "    'FALSE POSITIVE': 'FP',\n",
    "    'CANDIDATE': 'PC'\n",
    "})\n",
    "\n",
    "# Rename the disposition column to 'Status'\n",
    "k2_df = k2_df.rename(columns={'disposition': 'Status'})\n",
    "\n",
    "# Count the occurrences of each disposition type\n",
    "disposition_counts = k2_df['Status'].value_counts()\n",
    "\n",
    "# Display the counts for the requested dispositions\n",
    "print(\"Counts for K2Processed.csv:\")\n",
    "print(disposition_counts[['CP', 'FP', 'PC']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff06ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for KeplerProcessed.csv:\n",
      "Status\n",
      "FP    3735\n",
      "CP    2731\n",
      "PC    1356\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\k'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\k'\n",
      "C:\\Users\\anala\\AppData\\Local\\Temp\\ipykernel_26392\\1219379012.py:2: SyntaxWarning: invalid escape sequence '\\k'\n",
      "  kepler_df = pd.read_csv('../../data/processed\\keplerProcessed.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read the KeplerProcessed.csv file into a DataFrame\n",
    "kepler_df = pd.read_csv('../../data/processed\\keplerProcessed.csv')\n",
    "\n",
    "# Normalize disposition labels\n",
    "kepler_df['koi_disposition'] = kepler_df['koi_disposition'].replace({\n",
    "    'CONFIRMED': 'CP',\n",
    "    'FALSE POSITIVE': 'FP',\n",
    "    'CANDIDATE': 'PC'\n",
    "})\n",
    "\n",
    "# Rename the koi_disposition column to 'Status'\n",
    "kepler_df = kepler_df.rename(columns={'koi_disposition': 'Status'})\n",
    "\n",
    "# Count the occurrences of each value in the 'Status' column\n",
    "koi_disposition_counts = kepler_df['Status'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts for KeplerProcessed.csv:\")\n",
    "print(koi_disposition_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c428e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts for TOIProcessed.csv:\n",
      "Status\n",
      "PC     3008\n",
      "FP      812\n",
      "CP      605\n",
      "KP      365\n",
      "APC     299\n",
      "FA       55\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\anala\\AppData\\Local\\Temp\\ipykernel_26392\\1649327321.py:2: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  toi_df = pd.read_csv('../../data/processed\\TOIProcessed.csv')\n"
     ]
    }
   ],
   "source": [
    "# Read the TOIProcessed.csv file into a DataFrame\n",
    "toi_df = pd.read_csv('../../data/processed\\TOIProcessed.csv')\n",
    "\n",
    "# Rename the tfopwg_disp column to 'Status'\n",
    "toi_df = toi_df.rename(columns={'tfopwg_disp': 'Status'})\n",
    "\n",
    "# Count the occurrences of each value in the 'Status' column\n",
    "tfopwg_disp_counts = toi_df['Status'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Counts for TOIProcessed.csv:\")\n",
    "print(tfopwg_disp_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51478f6a",
   "metadata": {},
   "source": [
    "## Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "447780ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl_name</th>\n",
       "      <th>hostname</th>\n",
       "      <th>default_flag</th>\n",
       "      <th>Status</th>\n",
       "      <th>disp_refname</th>\n",
       "      <th>sy_snum</th>\n",
       "      <th>sy_pnum</th>\n",
       "      <th>discoverymethod</th>\n",
       "      <th>disc_year</th>\n",
       "      <th>disc_facility</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_trandeperr2</th>\n",
       "      <th>pl_insol</th>\n",
       "      <th>pl_eqt</th>\n",
       "      <th>st_tmag</th>\n",
       "      <th>st_tmagerr1</th>\n",
       "      <th>st_tmagerr2</th>\n",
       "      <th>st_dist</th>\n",
       "      <th>st_disterr1</th>\n",
       "      <th>st_disterr2</th>\n",
       "      <th>toi_created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CP</td>\n",
       "      <td>Espinoza et al. 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CP</td>\n",
       "      <td>Espinoza et al. 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BD+20 594 b</td>\n",
       "      <td>BD+20 594</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CP</td>\n",
       "      <td>Espinoza et al. 2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EPIC 201111557.01</td>\n",
       "      <td>EPIC 201111557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>Livingston et al. 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EPIC 201127519.01</td>\n",
       "      <td>EPIC 201127519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PC</td>\n",
       "      <td>Livingston et al. 2018</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Transit</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>K2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             pl_name        hostname  default_flag Status  \\\n",
       "0        BD+20 594 b       BD+20 594           0.0     CP   \n",
       "1        BD+20 594 b       BD+20 594           0.0     CP   \n",
       "2        BD+20 594 b       BD+20 594           1.0     CP   \n",
       "3  EPIC 201111557.01  EPIC 201111557           1.0     PC   \n",
       "4  EPIC 201127519.01  EPIC 201127519           1.0     PC   \n",
       "\n",
       "             disp_refname  sy_snum  sy_pnum discoverymethod  disc_year  \\\n",
       "0    Espinoza et al. 2016      1.0      1.0         Transit     2016.0   \n",
       "1    Espinoza et al. 2016      1.0      1.0         Transit     2016.0   \n",
       "2    Espinoza et al. 2016      1.0      1.0         Transit     2016.0   \n",
       "3  Livingston et al. 2018      1.0      0.0         Transit     2018.0   \n",
       "4  Livingston et al. 2018      1.0      0.0         Transit     2018.0   \n",
       "\n",
       "  disc_facility  ... pl_trandeperr2 pl_insol  pl_eqt  st_tmag  st_tmagerr1  \\\n",
       "0            K2  ...            NaN      NaN     NaN      NaN          NaN   \n",
       "1            K2  ...            NaN      NaN     NaN      NaN          NaN   \n",
       "2            K2  ...            NaN      NaN     NaN      NaN          NaN   \n",
       "3            K2  ...            NaN      NaN     NaN      NaN          NaN   \n",
       "4            K2  ...            NaN      NaN     NaN      NaN          NaN   \n",
       "\n",
       "   st_tmagerr2  st_dist  st_disterr1  st_disterr2  toi_created  \n",
       "0          NaN      NaN          NaN          NaN          NaN  \n",
       "1          NaN      NaN          NaN          NaN          NaN  \n",
       "2          NaN      NaN          NaN          NaN          NaN  \n",
       "3          NaN      NaN          NaN          NaN          NaN  \n",
       "4          NaN      NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Info of the combined DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14190 entries, 0 to 14189\n",
      "Columns: 124 entries, pl_name to toi_created\n",
      "dtypes: float64(105), object(19)\n",
      "memory usage: 13.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Combine the three dataframes\n",
    "combined_df = pd.concat([k2_df, kepler_df, toi_df], ignore_index=True)\n",
    "# Display the first few rows and the info of the combined dataframe to verify\n",
    "print(\"Combined DataFrame:\")\n",
    "display(combined_df.head())\n",
    "print(\"\\nInfo of the combined DataFrame:\")\n",
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d7d9c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas restantes en kepler_df: 5268\n"
     ]
    }
   ],
   "source": [
    "# Elimina el 50% de las filas que contienen valores nulos en kepler_df\n",
    "num_rows_to_drop = int(kepler_df.isnull().any(axis=1).sum() * 0.5)\n",
    "rows_with_nan = kepler_df[kepler_df.isnull().any(axis=1)].index[:num_rows_to_drop]\n",
    "kepler_df = kepler_df.drop(index=rows_with_nan).reset_index(drop=True)\n",
    "\n",
    "# Mostrar el n√∫mero de filas despu√©s de eliminar\n",
    "print(f\"Filas restantes en kepler_df: {len(kepler_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bec1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

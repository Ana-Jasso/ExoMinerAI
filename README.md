# ExoMinerAI üöÄüî≠

ExoMinerAI es un proyecto para entrenar y evaluar modelos de machine learning destinados a identificar exoplanetas utilizando datos p√∫blicos de Kepler, K2 y TESS.

Este repositorio contiene scripts de preprocesamiento, notebooks de an√°lisis exploratorio, modelos y una peque√±a interfaz web para visualizar resultados.

## √çndice

- Descripci√≥n
- R√°pido inicio (Quickstart)
- Estructura del proyecto
- Datos
- Uso del modelo (CLI)
- Notebooks
- Desarrollo y contribuci√≥n
- Licencia

## Descripci√≥n

El objetivo es facilitar la preparaci√≥n de datos procedentes de diferentes misiones astron√≥micas, entrenar clasificadores (p. ej. Random Forest) y exponer utilidades para predecir la clasificaci√≥n de eventos transitivos (Confirmado / Candidato / Falso positivo). Tambi√©n incluye una peque√±a web para exploraci√≥n.

## R√°pido inicio (Quickstart)

1) Clonar el repositorio:

```powershell
git clone <tu-repo-url>
cd ExoMinerAI
```

2) Crear un entorno virtual e instalar dependencias (si tienes un `requirements.txt`):

```powershell
python -m venv .venv; .\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
# Nota: hay un requirements en src/webapp/ si usas la web
pip install -r src/webapp/requirements.txt
```

3) Aseg√∫rate de que las rutas de los archivos CSV est√°n en `data/raw/` y `data/processed/` (el repositorio incluye ejemplos en `data/`).

4) Ejecuta el script de predicci√≥n (ejemplo):

```powershell
python src/preprocessing/rf_predict.py --ra 123.45 --dec -23.4 --pl_orbper 10.5 --pl_rade 2.3 --pl_insol 150.0 --pl_eqt 500 --st_teff 5500 --st_logg 4.4 --st_rad 1.0 --st_tmag 12.3 --mission TESS
```

El script entrenar√° y guardar√° un modelo cacheado en `src/preprocessing/rf_model.joblib` si no existe y luego imprimir√° la etiqueta predicha (`CONFIRMED`, `CANDIDATE`, `FALSE`, etc.). A√±ade `--retrain` para forzar reentrenamiento.

## Estructura del proyecto

Resumen de archivos y carpetas m√°s relevantes:

- `data/`
  - `raw/` : CSVs originales (Kepler, K2, TESS)
  - `processed/` : CSVs limpiados y preparados para modelado (ej.: `cleaned_datasets.csv`)
- `src/preprocessing/` : Notebooks y scripts de limpieza y preparaci√≥n (`concat_files.ipynb`, `k2_cleaning.ipynb`, etc.). Contiene `rf_predict.py` para predicci√≥n por CLI.
- `src/models/` : (vac√≠o/ubicaci√≥n prevista) para scripts de entrenamiento/guardado de modelos.
- `src/webapp/` : C√≥digo de la aplicaci√≥n web (Flask/Streamlit/FastAPI) y sus dependencias.
- `notebooks/` : Notebooks de exploraci√≥n y EDA.

## Datos

Rutas usadas en los notebooks y scripts del proyecto (relativas al repositorio):

- Datos sin procesar: `data/raw/Kepler_cumulative_*.csv`, `data/raw/k2pandc_*.csv`, `data/raw/TESS_TOI_*.csv`
- Datos procesados/limpios: `data/processed/cleaned_datasets.csv`, `data/processed/encoded_datasets.csv`

Si usas los scripts desde `src/preprocessing/`, las rutas relativas en los notebooks usan `../../data/...` para alcanzar la carpeta `data/` en la ra√≠z del proyecto.

## Uso del modelo (rf_predict)

El script `src/preprocessing/rf_predict.py` ofrece una interfaz simple por l√≠nea de comandos que recibe las 11 caracter√≠sticas principales y devuelve la predicci√≥n de `disposition_norm`.

Campos esperados (orden/flags CLI):

- `--ra` (float)
- `--dec` (float)
- `--pl_orbper` (float)
- `--pl_rade` (float)
- `--pl_insol` (float)
- `--pl_eqt` (float)
- `--st_teff` (float)
- `--st_logg` (float)
- `--st_rad` (float)
- `--st_tmag` (float)
- `--mission` (string) ‚Äî ejemplos: `TESS`, `Kepler`, `K2`

Ejemplo:

```powershell
python src/preprocessing/rf_predict.py --ra 123.45 --dec -23.4 --pl_orbper 10.5 --pl_rade 2.3 --pl_insol 150.0 --pl_eqt 500 --st_teff 5500 --st_logg 4.4 --st_rad 1.0 --st_tmag 12.3 --mission TESS
```

Salida: una sola l√≠nea con la etiqueta predicha (por ejemplo `CONFIRMED`).

Problemas comunes:
- Si aparece un error de archivo no encontrado, verifica tu directorio de trabajo o que `data/processed/cleaned_datasets.csv` exista.
- Si `mission` tiene un valor que no apareci√≥ en el entrenamiento, el script devolver√° un error; puedes reentrenar el modelo usando `--retrain`.

## Notebooks

Los notebooks en `src/preprocessing/` y `notebooks/` contienen pasos de limpieza, uni√≥n de cat√°logos y EDA. Para reproducir los resultados:

1. Abre el notebook en Jupyter (o VS Code).
2. Ejecuta las celdas de import y carga de datos (aseg√∫rate que las rutas relativas a `data/` son correctas).

Consejo: usa rutas basadas en `pathlib.Path` cuando conviertas los notebooks a scripts para mayor robustez.

## Desarrollo y contribuci√≥n

- A√±ade issues para bugs o features.
- Usa ramas para cambios grandes y PRs para revisi√≥n.
- A√±ade tests en `tests/` cuando modifiques l√≥gica de preprocesamiento o modelos.

## Licencia y contacto

Este repositorio no incluye una licencia espec√≠fica por defecto. A√±ade un `LICENSE` si quieres que sea open-source con condiciones claras (MIT, Apache-2.0, etc.).

Contacto: abre un issue en el repositorio o contacta al mantenedor del proyecto.

---

Recursos externos: algunos notebooks y ejemplos fueron creados a partir de cat√°logos p√∫blicos de Kepler, K2 y TESS proporcionados por la NASA y sus colaboradores.
